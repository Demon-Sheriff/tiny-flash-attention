# tiny-flash-attention

`this repo is my attempt at re-creating the flash-attention paper in cuda` 

the paper can be found [here](https://arxiv.org/pdf/2205.14135)

