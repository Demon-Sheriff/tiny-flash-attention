# tiny-flash-attention

`this repo is my attempt at re-creating the [flash-attention](https://arxiv.org/pdf/2205.14135) paper in cuda` 

